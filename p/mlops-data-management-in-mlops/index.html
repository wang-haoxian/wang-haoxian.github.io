<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="My two cents on data management in MLOps based on my personal experiences."><title>[MLOps] Data Management in MLOps</title><link rel=canonical href=https://www.haoxian.icu/p/mlops-data-management-in-mlops/><link rel=stylesheet href=/scss/style.min.833d6eed45de56f48306bf57268d5b8cdfc8a60e8e7bdc99810464fcd033f7c6.css><meta property='og:title' content="[MLOps] Data Management in MLOps"><meta property='og:description' content="My two cents on data management in MLOps based on my personal experiences."><meta property='og:url' content='https://www.haoxian.icu/p/mlops-data-management-in-mlops/'><meta property='og:site_name' content="Haoxian's Blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='MLOps'><meta property='article:tag' content='Data Management'><meta property='article:tag' content='NLP'><meta property='article:tag' content='DVC'><meta property='article:tag' content='S3'><meta property='article:tag' content='MinIO'><meta property='article:tag' content='MLFlow'><meta property='article:published_time' content='2023-11-30T11:00:06+09:00'><meta property='article:modified_time' content='2023-11-30T11:00:06+09:00'><meta name=twitter:title content="[MLOps] Data Management in MLOps"><meta name=twitter:description content="My two cents on data management in MLOps based on my personal experiences."><link rel="shortcut icon" href=/favicon.svg></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_a8dd701257cc3205.jpg width=300 height=400 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Haoxian's Blog</a></h1><h2 class=site-description>From NLP to MLOps and LLM</h2></div></header><ol class=menu-social><li><a href=https://github.com/wang-haoxian target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#what-is-data-management-in-mlops>What is Data Management in MLOps?</a></li><li><a href=#why-do-we-need-to-manage-data-in-mlops>Why do we need to manage data in MLOps?</a></li><li><a href=#what-are-the-requirements-for-data-management-in-mlops>What are the requirements for data management in MLOps?</a><ol><li><a href=#traceability-reproducibility-versioning>Traceability, Reproducibility, Versioning</a></li><li><a href=#scalability-flexibility-cost-performance>Scalability, Flexibility, Cost, Performance</a></li><li><a href=#simplicity-automation-collaboration-security>Simplicity, Automation, Collaboration, Security</a></li></ol></li><li><a href=#data-design-pattern>Data Design Pattern</a><ol><li><a href=#the-medallion-architecture>The Medallion Architecture</a><ol><li><a href=#bronze-layer>Bronze Layer</a></li><li><a href=#silver-layer>Silver Layer</a></li><li><a href=#gold-layer>Gold Layer</a></li><li><a href=#free-to-choose-the-data-store>Free to choose the data store</a></li></ol></li></ol></li><li><a href=#data-quality>Data Quality</a></li><li><a href=#data-versioning>Data Versioning</a><ol><li><a href=#general-tools-for-data-versioning>General tools for data versioning</a></li><li><a href=#home-made-solution>Home made solution</a></li></ol></li><li><a href=#describe-the-data-with-metadata>Describe the data with metadata</a><ol><li><a href=#accessibility-of-the-metadata>Accessibility of the metadata</a></li><li><a href=#what-to-add-to-the-metadata>What to add to the metadata</a></li></ol></li><li><a href=#example-of-html-data-for-nlp-with-the-medallion-architecture>Example of HTML data for NLP with the Medallion Architecture</a><ol><li><a href=#pipeline>Pipeline</a></li><li><a href=#architecture>Architecture</a></li><li><a href=#overview-of-different-layers>Overview of different layers</a><ol><li><a href=#the-nomclature-for-the-paths-to-the-data-in-s3>The nomclature for the paths to the data in S3</a></li><li><a href=#bronze-layer-1>Bronze Layer</a></li><li><a href=#silver-layer-1>Silver Layer</a></li><li><a href=#gold-layer-1>Gold Layer</a></li><li><a href=#post-train-layer>Post Train Layer</a></li></ol></li></ol></li><li><a href=#conclusion>Conclusion</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/p/mlops-data-management-in-mlops/>[MLOps] Data Management in MLOps</a></h2><h3 class=article-subtitle>My two cents on data management in MLOps based on my personal experiences.</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published datetime=2023-11-30T11:00:06+09:00>Nov 30, 2023</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>21 minute read</time></div></footer></div></header><section class=article-content><h2 id=what-is-data-management-in-mlops>What is Data Management in MLOps?</h2><p>Data management in MLOps is the process of managing data in the machine learning lifecycle. It includes data collection, data storage, data versioning, data quality, data monitoring, data lineage, data governance, and data security.<br>In this article, we will focus on data versioning, data storage, and data quality.
I have checked several ways to manage data in MLOps, and I will share my experience with you. Please feel free to leave a comment if you have any questions or suggestions. This is not a data engineering article, so my focus is not on the data engineering part. I will try to keep it simple and easy to understand.</p><h2 id=why-do-we-need-to-manage-data-in-mlops>Why do we need to manage data in MLOps?</h2><p>There are saying that most of works of data scientists are data cleaning and data preprocessing.<br>This is true.
In the machine learning lifecycle, data is the most important part. The quality of data will directly affect the performance of the model. As we what we say all the time: &ldquo;Garbage in, garbage out.&rdquo;
Therefore, we need to manage data in MLOps.<br>It&rsquo;s a big challenge to manage data in MLOps, because data is always changing. Imagine that you have a dataset collected from production, and you have trained a model with the dataset. After a while, the data in production has changed. You need to retrain the model with the new dataset. How can you manage the data and the model? For a simple model, you may have many different kind of processings. Take HTML as an example, you may have different processings like:</p><ul><li>removing tags</li><li>removing stop words</li><li>removing punctuation</li><li>removing numbers</li><li>removing special characters</li><li>Normalizing URLs</li><li>removing emojis</li><li>removing non-target langugae words</li><li>removing non-ASCII characters</li><li>removing non-printable characters</li></ul><p>For some of the processings, you can do it on the fly while training/inference, but some of them you need to do it before training since it&rsquo;s not your part of pipeline. Or you will need to align with other downstream users of the same data source. For the sake of cost, you may want to do it once and for all but with possible different versions.
Meanwhile, the pipeline is separated to several steps, and each step may have different requirements for the data. For example, the first step may need the raw data, and the second step may need the data after removing tags.
When the dataset is big enough, it&rsquo;s hard to manage the data. Thus we need to manage the data in MLOps.</p><h2 id=what-are-the-requirements-for-data-management-in-mlops>What are the requirements for data management in MLOps?</h2><p>I am not here to talk about using very advanced tools like Delta Lake or Apache Iceberg. They have some fancy features like time travel. But for a small team or a small project, they are too heavy and the cost may be too high. So I will focus on the principles of data management in MLOps by taking some ideas from data engineering.
From my personal experiences, the requirements for data management in MLOps are:</p><ul><li>Traceability: We need to know where the data comes from, and how the data is processed. The metadata of the data should be managed.</li><li>Reproducibility: We need to be able to reproduce the data with certain procedures in case we delete the data temporarily.</li><li>Versioning: Data should be managed with versions, and we need to be able to access the data with different versions.</li><li>Scalability: The ability to manage the data in a scalable way with business growth.</li><li>Flexibility: The possibility of changing the processing of the data.</li><li>Cost: The cost should be reasonable for the business.</li><li>Performance: There are data requires cocurrent read/write, and we need to manage the data with performance.</li><li>Simplicity: New members should be able to understand the data management and tools easily.</li><li>Automation: The pipeline should be able to run automatically with as less as possible human intervention, just like a CI/CD pipeline.</li><li>Collaboration: The management process should allow multiple people to work on the same data.</li><li>Security: We need to define the scope of access control for different people.</li></ul><p>This is not an exhaustive list, but it&rsquo;s a good start.
I separate these requirements into three groups:</p><ul><li>Traceability, Reproducibility, Versioning</li><li>Scalability, Flexibility, Cost, Performance</li><li>Simplicity, Automation, Collaboration, Security</li></ul><h3 id=traceability-reproducibility-versioning>Traceability, Reproducibility, Versioning</h3><p>These three requirements represents the most general ideas in people&rsquo;s mind when talking about data management. I put them together because they are highly coupled.
Traceability means we need to know where the data comes from, and how the data is processed.
Reproducibility means we need to be able to reproduce the data with some given steps.
Versioning means we need to be able to manage the versions of the data incrementally.
These three requirements together means we are able to understand at each step when and how the data is processed, with what kind of upstream data source, and then we are able to reproduce each step with the information we have.
What we need for these three requirements are basically a set of informations to describe the runs of the pipeline.</p><h3 id=scalability-flexibility-cost-performance>Scalability, Flexibility, Cost, Performance</h3><p>These four elements together force us to think about the most efficient way to manage the data. Sevceral questions we need to ask ourselves are:</p><ul><li>How to manage the data when the data is big enough?</li><li>How to manage the data with the changing business requirements?</li><li>How to manage the data with a reasonable cost?</li></ul><p>We need to find out the solution to make a balance between these four elements. It&rsquo;s easy to use a huge Google BigQuery to manage the data at a very scalable and performant way, at the price of potentially sacrificing the flexibility and it may be too expensive. It&rsquo;s also easy to allocate unlimited size of bucket storage in AWS S3, but it may be too expensive and we may lose some performance. Some advanced modern data warehouses like Snowflake may be a good choice, but it add too much overhead for a small team or a small project.<br>All I want to say it&rsquo;s that there are no silver bullet, and we need to find out the best solution for our own case. Sometimes git-lfs is our best friend, sometimes it&rsquo;s not. Sometimes a simple S3 bucket will be nice. And in many cases DVC could be cool at some point.</p><h3 id=simplicity-automation-collaboration-security>Simplicity, Automation, Collaboration, Security</h3><p>These four elements comes together when there is more than one person working on the same project.<br>If the data is difficult to access, it will be hard to collaborate.
Collaboration comes with security concerns.<br>And bad automation will make things more complicated.
Automation could be the source of secret leaks.
A good solution should be at the balance of these four elements.
There are so many tools that can help with us. For example, Argo Workflow, Airflow, Dagster, etc.
Basically, we need a centralized place to click and run the pipeline, and we need to be able to manage the access control without knowing every detail of the pipeline.</p><h2 id=data-design-pattern>Data Design Pattern</h2><h3 id=the-medallion-architecture>The Medallion Architecture</h3><p>There are many ways to manage data in MLOps. I will introduce the Medallion Architecture for it&rsquo;s simplicity and flexibility. From this super cool article <a class=link href=https://www.databricks.com/glossary/medallion-architecture target=_blank rel=noopener>The Medallion Architecture</a> from Databricks, we can quickly build an idea of how to manage data in MLOps.
There are basically three layers in the Medallion Architecture:</p><ul><li>Bronze: Raw data</li><li>Silver: Cleaned and conformed data</li><li>Gold: curated business-level data / Feature Store</li></ul><h4 id=bronze-layer>Bronze Layer</h4><p>The Bronze layer is the raw data layer. It&rsquo;s the data that is collected from the data source. It has not been processed yet, it may contain some garbage data.Let&rsquo;s say there are data in format like JSON, but it&rsquo;s not well structured. You may see some missing fields, or some fields are not in the right format. It&rsquo;s not impossible that there are so many repeated data. You normally cannot read it directly without some processing.
Generally it&rsquo;s so called unstructured or semi-structured data. It&rsquo;s the data that is closest to the data source.</p><h4 id=silver-layer>Silver Layer</h4><p>The Silver layer is the cleaned and conformed data layer. It&rsquo;s the data that has been processed and cleaned. It may not contain all the information for the final tasks. For example, if you want to build a dataset to fine-tune a LLM for insurance domain, this layer may contain the data that is anonymized. It may not contain the data that is not related to the insurance domain.</p><h4 id=gold-layer>Gold Layer</h4><p>The Gold layer is the curated business-level data layer. It&rsquo;s the data that is ready to use for the final tasks. A good example is the Feature Store. It&rsquo;s the data that is ready to use for the training and inference. It&rsquo;s the data that is ready to use for the final tasks. If you are building a Retrieval Augmented Generation (RAG) system, it could be the Vector DB that contains the vectors of the documents.</p><h4 id=free-to-choose-the-data-store>Free to choose the data store</h4><p>With the Medallion Architecture, we can manage the data flexibly with necessary control without stuck to a single data storage. For example, the raw data can be stored in a S3 bucket with versioning, and the cleansed and bussiness data can be stored in a database like Postgres or Delta Lake. Each layer can be managed with different tools with different requirements, or if your organization has a centralized data platform, you can use the same tool to manage all the layers. It&rsquo;s important to adopt the right tool for the right layer based on your business requirements.</p><h2 id=data-quality>Data Quality</h2><p>Data quality is much more than just data cleaning. It&rsquo;s the process of ensuring the data is fit for the purpose. The data should be accurate, complete, consistent, and timely. However, in practice, it&rsquo;s not easy to achieve all the requirements. In MlOps, we tend to begin with relatively low quality data, and then improve the quality of the data incrementally. For example, the classic human-in-the-loop approach is a good way to improve the quality of the data and align with the business requirements.
There are also tools that can help us to improve the quality of the data. For example, <a class=link href=https://greatexpectations.io/gx-cloud target=_blank rel=noopener>Great Expectations</a> is a good tool to help us to define the expectations of the data, and then validate the data with the expectations. It&rsquo;s a good way to improve the quality of the data. There are also other tools like <a class=link href=https://griffin.apache.org target=_blank rel=noopener>Apache Griffin</a>, etc. But these are a little bit too heavy for a small team or a small project.
Another kind of data quality tools is something like <a class=link href=https://github.com/cleanlab/cleanlab target=_blank rel=noopener>CleanLab</a>. It&rsquo;s a tool to help us to identify the mislabeled data by analyzing the outliars. The strong connection between data quality and model quality makes it a good tool to improve the quality of the data semi-automatically.</p><h2 id=data-versioning>Data Versioning</h2><h3 id=general-tools-for-data-versioning>General tools for data versioning</h3><p>Data versioning is the process of managing the versions of the data. It&rsquo;s important to keep track of the versions of the data, and be able to access the data with different versions, hence we can reproduce the data with the same version.
There are many tools that can help us to manage the versions of the data. For example, <a class=link href=https://dvc.org/ target=_blank rel=noopener>DVC</a>, <a class=link href=https://git-lfs.com/ target=_blank rel=noopener>git-lfs</a>, <a class=link href=https://docs.neptune.ai/tutorials/data_versioning/ target=_blank rel=noopener>Neptune</a>, <a class=link href=https://www.pachyderm.com/ target=_blank rel=noopener>Pachyderm</a>, <a class=link href=https://github.com/treeverse/lakeFS target=_blank rel=noopener>lakeFS</a>, etc.</p><p>While DVC and git-lfs are more like a git extension, Neptune, Pachyderm, and lakeFS are more like a data lake. They are more like a centralized data platform. For a restrained budget, DVC and git-lfs are more suitable. For a big organization, tools like Neptune, Pachyderm, and lakeFS are good choices. And sometimes the infra team may be reluctant to add another tool to the stack, so we may need to use the existing tools like git-lfs.</p><h3 id=home-made-solution>Home made solution</h3><p>Sometimes we don&rsquo;t need to use any tools but well defined procedures. For example, we can use a S3 bucket to store the data, and use the folder structure to manage the versions of the data. It&rsquo;s simple and easy to understand, it&rsquo;s scalable with the business growth, and it&rsquo;s cost effective. The only drawback is that it&rsquo;s not easy to manage the access control in some fine-grained way. But it&rsquo;s not a big problem for a small team or a small project. With a proper defined toolkit and workflow, it&rsquo;s easy to manage the data with versioning this way.</p><h2 id=describe-the-data-with-metadata>Describe the data with metadata</h2><p>The dataset is often not obvious to understand. For instance, say you use parquets to store data, and you have a parquet file with 100 columns. It&rsquo;s not easy to understand the data without any metadata. If you use a data warehouse like Snowflake or Delta Lake, you have easy access to the metadata of the data because they are built-in. But if you use a S3 bucket to store the data, you need to manage the metadata by yourself.<br>In the point of view of data engineering, the major metadata of the data is the schema of the data. In the point of view of data science, the major metadata of the data is the statistics of the data. From a business point of view, the metadata we want to see is a self-explanatory description of the data which matches the business logic. And in NLP, we may want to see the text normalization rules, the tokenization rules, etc. This is to say, the metadata is a complex set of information that varies from different perspectives and use cases. For me, we need to manage the metadata in a strucutred way, and we need to be able to access the metadata easily.</p><h3 id=accessibility-of-the-metadata>Accessibility of the metadata</h3><p>The metadata should be positionned alongside the dataset. For databases, they are built-in. For more generic file systems like S3, we need to manage the metadata by ourselves. I would recommand formats that are easy to read and write, like JSON, YAML, or TOML, etc. This allows us to preview the metadata easily.<br>The reason to choose this kind of formats, is that we may want to use the metadata in the pipeline. For example, we may want to use the metadata to validate the data, or we may want to use the metadata to generate the documentation of the data. This requires the data to be in a structured format which can be easily parsed.<br>Sometimes an extract of the data is a good way to describe the data. It&rsquo;s a good idea to put an sample of the data alongside the dataset. We may not want to download the whole dataset to build a first impression of the data. And we can use the sample to explain the whole dataset and the pipeline to non technical people.</p><h3 id=what-to-add-to-the-metadata>What to add to the metadata</h3><p>I have made a list of possible metadata that we may want to manage:</p><ul><li>Description: What is the data about?</li><li>Data source: What&rsquo;s the upstream data source?</li><li>SHA1: Useful to check data integrity</li><li>Schema: Allows us to load the data easily</li><li>Statistics: help us to handle the data (like missing values, etc.)<ul><li>Number of rows</li><li>Number of columns</li></ul></li><li>Sample: A sample of the data if the data is compatible with the format, otherwise you may want it to be in a separate file</li><li>ETL pipeline stage: What&rsquo;s the current stage of the data in the pipeline?</li><li>Exectuion time of the pipeline</li><li>Mapping between the columns and the business logic</li></ul><p>Personally, there is always a rule of thumb to determine the complexity of something. That is, if someone new onboarding the project, how long will it take for him/her to understand the thing. The metadata here should be auto-representative not only for the data itself, but also for the pipeline or the code.</p><h2 id=example-of-html-data-for-nlp-with-the-medallion-architecture>Example of HTML data for NLP with the Medallion Architecture</h2><p>We have talked about HTML data in the beginning of this article. Let&rsquo;s take a look at how we can manage the data with the Medallion Architecture. Let&rsquo;s assume that you want to build a system to categorize the HTML documents. The data source is a crawler that crawls the HTML documents from the Internet, at a rate of 1000 documents per day. The output of the crawler is a JSON file that contains the HTML documents stored in a S3 bucket.
In this example, we will limit the tools to show the case in a restrained budget. So we only use git and S3 with MLFlow. All workflows run on ArgoWorkflow or Airflow.
Let&rsquo;s name this project as <code>html-classification</code> and let&rsquo;s begin.</p><h3 id=pipeline>Pipeline</h3><p>The pipeline will be essentially something like this:
<img src=/p/mlops-data-management-in-mlops/pipeline%20overview.png width=3605 height=1468 srcset="/p/mlops-data-management-in-mlops/pipeline%20overview_hu_3a1f071abe1c57f1.png 480w, /p/mlops-data-management-in-mlops/pipeline%20overview_hu_690982e0bbb0a8e1.png 1024w" loading=lazy alt="Data Pipeline Illustration" class=gallery-image data-flex-grow=245 data-flex-basis=589px></p><h3 id=architecture>Architecture</h3><p>The architecture is illustrated as below:
<img src=/p/mlops-data-management-in-mlops/data%20management%20overview.png width=2644 height=1548 srcset="/p/mlops-data-management-in-mlops/data%20management%20overview_hu_b276f495a9c1d039.png 480w, /p/mlops-data-management-in-mlops/data%20management%20overview_hu_9f0b2ecbdd5f3649.png 1024w" loading=lazy alt="Data Architecture Illustration" class=gallery-image data-flex-grow=170 data-flex-basis=409px></p><h3 id=overview-of-different-layers>Overview of different layers</h3><h4 id=the-nomclature-for-the-paths-to-the-data-in-s3>The nomclature for the paths to the data in S3</h4><p>We are going to setup a bunch of rules since we are using S3 to store the data. We will use the following nomclature for the paths to the data in S3:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=l>s3://&lt;bucket_name&gt;/html-classification/&lt;stage&gt;/&lt;date-of-data&gt;/&lt;dataset&gt;</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><h4 id=bronze-layer-1>Bronze Layer</h4><p>At this stage, the most direct input is the HTML documents collected by the crawler. It can be the output of an ingestion workflow that streams the documents from some message queue system to process it in a batch way. The output of the ingestion workflow is a JSON file that contains the HTML documents. As a personal preference, I use JSONL format to facilitate the reading in streaming mode.<br>The format looks like:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Json data-lang=Json><span class=line><span class=cl><span class=err>#</span> <span class=err>s</span><span class=mi>3</span><span class=err>:</span><span class=c1>//&lt;bucket_name&gt;/html-classification/raw/2021-09-01/html-documents.json
</span></span></span><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://www.example.com/giberish_html_?&#34;</span><span class=p>,</span><span class=nt>&#34;html&#34;</span><span class=p>:</span> <span class=s2>&#34;&lt;html&gt;&lt;body&gt;...&lt;/body&gt;&lt;/html&gt;&#34;</span><span class=p>,</span><span class=nt>&#34;timestamp&#34;</span><span class=p>:</span> <span class=s2>&#34;2021-09-01T00:00:00+09:00&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://www.example2.co/giberish_html_?&#34;</span><span class=p>,</span><span class=nt>&#34;html&#34;</span><span class=p>:</span> <span class=s2>&#34;&lt;html&gt;&lt;body&gt;...&lt;/body&gt;&lt;/html&gt;&#34;</span><span class=p>,</span><span class=nt>&#34;timestamp&#34;</span><span class=p>:</span> <span class=s2>&#34;2021-09-02T00:00:00+09:00&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=err>...</span>
</span></span></code></pre></td></tr></table></div></div><p>Metadata:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl>-<span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Description</span><span class=p>:</span><span class=w> </span><span class=l>The raw HTML documents collected by the crawler. </span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Data source</span><span class=p>:</span><span class=w> </span><span class=l>The crawler</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Date of data creation</span><span class=p>:</span><span class=w> </span><span class=ld>2021-09-01</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>workflow-name</span><span class=p>:</span><span class=w> </span><span class=l>crawler-to-s3</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>SHA1</span><span class=p>:</span><span class=w> </span><span class=l>8b8ae027744d2f920eb1aeee676d589957de40cc</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Schema</span><span class=p>:</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>html</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Statistics</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>Number of rows</span><span class=p>:</span><span class=w> </span><span class=m>1000</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>Number of columns</span><span class=p>:</span><span class=w> </span><span class=m>3</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Sample</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://www.example.com/giberish_html_?&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>html</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;&lt;html&gt;&lt;body&gt;...&lt;/body&gt;&lt;/html&gt;&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2021-09-01T00:00:00+09:00&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://www.example2.co/giberish_html_?&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>html</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;&lt;html&gt;&lt;body&gt;...&lt;/body&gt;&lt;/html&gt;&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2021-09-02T00:00:00+09:00&#34;</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><h4 id=silver-layer-1>Silver Layer</h4><p>At this stage, we begin to have some much more structured data.</p><h5 id=url-normalization>URL Normalization</h5><p>The first step is to normalize the URLs, with some simple deduplication with title (This is a rather arbitrary process as example only. In real life, the dedup should be much more complex and taking account more information. For example, the same page with different timestamps. We tend to keep the fresh copy). The output of this step will be like:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Json data-lang=Json><span class=line><span class=cl><span class=err>#</span> <span class=err>s</span><span class=mi>3</span><span class=err>:</span><span class=c1>//&lt;bucket_name&gt;/html-classification/preprocess/url-normalization/2021-09-02/html-documents.json
</span></span></span><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://www.example.com&#34;</span><span class=p>,</span><span class=nt>&#34;html&#34;</span><span class=p>:</span> <span class=s2>&#34;&lt;html&gt;&lt;body&gt;...&lt;/body&gt;&lt;/html&gt;&#34;</span><span class=p>,</span><span class=nt>&#34;timestamp&#34;</span><span class=p>:</span> <span class=s2>&#34;2021-09-01T00:00:00+09:00&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://www.example2.com&#34;</span><span class=p>,</span><span class=nt>&#34;html&#34;</span><span class=p>:</span> <span class=s2>&#34;&lt;html&gt;&lt;body&gt;...&lt;/body&gt;&lt;/html&gt;&#34;</span><span class=p>,</span><span class=nt>&#34;timestamp&#34;</span><span class=p>:</span> <span class=s2>&#34;2021-09-02T00:00:00+09:00&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=err>...</span>
</span></span></code></pre></td></tr></table></div></div><p>Metadata:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl>-<span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Description</span><span class=p>:</span><span class=w> </span><span class=l>The raw HTML documents collected by the crawler, with basic deduplication and normalization of the URLs.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Data source</span><span class=p>:</span><span class=w> </span><span class=l>s3://&lt;bucket_name&gt;/html-classification/raw/2021-09-01/html-documents.json</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Date of data creation</span><span class=p>:</span><span class=w> </span><span class=ld>2021-09-02</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>workflow-name</span><span class=p>:</span><span class=w> </span><span class=l>ingestion</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>SHA1</span><span class=p>:</span><span class=w> </span><span class=l>da4eec8e1ffe93df6b8a768ac78d98b3879a5baa</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Schema</span><span class=p>:</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>html</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Statistics</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>Number of rows</span><span class=p>:</span><span class=w> </span><span class=m>998</span><span class=w> </span><span class=c># 2 duplicated rows removed</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>Number of columns</span><span class=p>:</span><span class=w> </span><span class=m>3</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Sample</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://www.example.com&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>html</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;&lt;html&gt;&lt;body&gt;...&lt;/body&gt;&lt;/html&gt;&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2021-09-01T00:00:00+09:00&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://www.example2.com&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>html</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;&lt;html&gt;&lt;body&gt;...&lt;/body&gt;&lt;/html&gt;&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2021-09-02T00:00:00+09:00&#34;</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><p>This will allow us to have unique URLs for the same document, and the url can be used as the primary key of the data.</p><h5 id=html-parsing>HTML Parsing</h5><p>This time the format will be like:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Json data-lang=Json><span class=line><span class=cl><span class=err>#</span> <span class=err>s</span><span class=mi>3</span><span class=err>:</span><span class=c1>//&lt;bucket_name&gt;/html-classification/preprocess/html-parsing/2021-09-02/html-documents.json
</span></span></span><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://www.example.com&#34;</span><span class=p>,</span><span class=nt>&#34;title&#34;</span><span class=p>:</span> <span class=s2>&#34;Example&#34;</span><span class=p>,</span><span class=nt>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;This is an example.&#34;</span><span class=p>,</span><span class=nt>&#34;timestamp&#34;</span><span class=p>:</span> <span class=s2>&#34;2021-09-01T00:00:00+09:00&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://www.example2.com&#34;</span><span class=p>,</span><span class=nt>&#34;title&#34;</span><span class=p>:</span> <span class=s2>&#34;Example2&#34;</span><span class=p>,</span><span class=nt>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;This is an example2.&#34;</span><span class=p>,</span><span class=nt>&#34;timestamp&#34;</span><span class=p>:</span> <span class=s2>&#34;2021-09-02T00:00:00+09:00&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=err>...</span>
</span></span></code></pre></td></tr></table></div></div><p>Metadata:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl>-<span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Description</span><span class=p>:</span><span class=w> </span><span class=l>HTML documents with title and content extracted. </span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Data source</span><span class=p>:</span><span class=w> </span><span class=l>s3://&lt;bucket_name&gt;/html-classification/preprocess/url-normalization/2021-09-02/html-documents.json</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Date of data creation</span><span class=p>:</span><span class=w> </span><span class=ld>2021-09-02</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>workflow-name</span><span class=p>:</span><span class=w> </span><span class=l>html-parsing</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>SHA1</span><span class=p>:</span><span class=w> </span><span class=l>8b8ae027744d2f920eb1aeee676d589957de40cc</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Schema</span><span class=p>:</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>title</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>content</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Statistics</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>Number of rows</span><span class=p>:</span><span class=w> </span><span class=m>998</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>Number of columns</span><span class=p>:</span><span class=w> </span><span class=m>4</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Sample</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://www.example.com&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>title</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Example&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>content</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;This is an example.&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2021-09-01T00:00:00+09:00&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://www.example2.com&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>title</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Example2&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>content</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;This is an example2.&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2021-09-02T00:00:00+09:00&#34;</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><p>This is just an illustration format. To be more realistic, we may want to have more information like the metadata of the page, language of the document, the encoding of the document, etc. But hey, we can use some NLP tools to process the data.</p><h5 id=text-normalization>Text Normalization</h5><p>Now we want to apply some text normalization rules to the content. The choice of the rules depends on the business requirements. For example, we may want to remove the stop words, remove the punctuation, remove the numbers, remove the special characters, etc. And this could make huge difference for the final performance of the model. In this example, we could have several different versions of the data with different text normalization rules. And the metadata should come in handy to help us to understand the data.</p><h6 id=version-1>Version 1</h6><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Json data-lang=Json><span class=line><span class=cl><span class=err>#</span> <span class=err>s</span><span class=mi>3</span><span class=err>:</span><span class=c1>//&lt;bucket_name&gt;/html-classification/preprocess/text-normalization/v1/2021-09-02/html-documents.json
</span></span></span><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://www.example.com&#34;</span><span class=p>,</span><span class=nt>&#34;title&#34;</span><span class=p>:</span> <span class=s2>&#34;example&#34;</span><span class=p>,</span><span class=nt>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;this is an example.&#34;</span><span class=p>,</span><span class=nt>&#34;timestamp&#34;</span><span class=p>:</span> <span class=s2>&#34;2021-09-01T00:00:00+09:00&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://www.example2.com&#34;</span><span class=p>,</span><span class=nt>&#34;title&#34;</span><span class=p>:</span> <span class=s2>&#34;example2&#34;</span><span class=p>,</span><span class=nt>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;this is an example2.&#34;</span><span class=p>,</span><span class=nt>&#34;timestamp&#34;</span><span class=p>:</span> <span class=s2>&#34;2021-09-02T00:00:00+09:00&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=err>...</span>
</span></span></code></pre></td></tr></table></div></div><p>Metadata:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl>-<span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Description</span><span class=p>:</span><span class=w> </span><span class=l>HTML documents with title and content extracted, and text normalization applied. </span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Data source</span><span class=p>:</span><span class=w> </span><span class=l>s3://&lt;bucket_name&gt;/html-classification/preprocess/html-parsing/2021-09-02/html-documents.json</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Date of data creation</span><span class=p>:</span><span class=w> </span><span class=ld>2021-09-03</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>workflow-name</span><span class=p>:</span><span class=w> </span><span class=l>text-normalization-v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>process</span><span class=p>:</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>remove punctuation</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>remove special characters</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>SHA1</span><span class=p>:</span><span class=w> </span><span class=l>8b8ae027744d2f920eb1aeee676d589957de40cc</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Schema</span><span class=p>:</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>title</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>content</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Statistics</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>Number of rows</span><span class=p>:</span><span class=w> </span><span class=m>998</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>Number of columns</span><span class=p>:</span><span class=w> </span><span class=m>4</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Sample</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://www.example.com&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>title</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;example&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>content</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;this is an example&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2021-09-01T00:00:00+09:00&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://www.example2.com&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>title</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;example2&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>content</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;this is an example2&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2021-09-02T00:00:00+09:00&#34;</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><h6 id=version-2>Version 2</h6><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Json data-lang=Json><span class=line><span class=cl><span class=err>#</span> <span class=err>s</span><span class=mi>3</span><span class=err>:</span><span class=c1>//&lt;bucket_name&gt;/html-classification/preprocess/text-normalization/v2/2021-09-02/html-documents.json
</span></span></span><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://www.example.com&#34;</span><span class=p>,</span><span class=nt>&#34;title&#34;</span><span class=p>:</span> <span class=s2>&#34;example&#34;</span><span class=p>,</span><span class=nt>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;this be an example.&#34;</span><span class=p>,</span><span class=nt>&#34;timestamp&#34;</span><span class=p>:</span> <span class=s2>&#34;2021-09-01T00:00:00+09:00&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://www.example2.com&#34;</span><span class=p>,</span><span class=nt>&#34;title&#34;</span><span class=p>:</span> <span class=s2>&#34;example2&#34;</span><span class=p>,</span><span class=nt>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;this be an example2.&#34;</span><span class=p>,</span><span class=nt>&#34;timestamp&#34;</span><span class=p>:</span> <span class=s2>&#34;2021-09-02T00:00:00+09:00&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=err>...</span>
</span></span></code></pre></td></tr></table></div></div><p>Metadata:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl>-<span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Description</span><span class=p>:</span><span class=w> </span><span class=l>HTML documents with title and content extracted, and text normalization applied.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Data source</span><span class=p>:</span><span class=w> </span><span class=l>s3://&lt;bucket_name&gt;/html-classification/preprocess/html-parsing/2021-09-02/html-documents.json</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Date of data creation</span><span class=p>:</span><span class=w> </span><span class=ld>2021-09-03</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>workflow-name</span><span class=p>:</span><span class=w> </span><span class=l>text-normalization-v2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>process</span><span class=p>:</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>remove special characters</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>verbe lematization</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>SHA1</span><span class=p>:</span><span class=w> </span><span class=l>8b8ae027744d2f920eb1aeee676d589957de40cc</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Schema</span><span class=p>:</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>title</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>content</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Statistics</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>Number of rows</span><span class=p>:</span><span class=w> </span><span class=m>998</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>Number of columns</span><span class=p>:</span><span class=w> </span><span class=m>4</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Sample</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://www.example.com&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>title</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;example&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>content</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;this be an example.&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2021-09-01T00:00:00+09:00&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://www.example2.com&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>title</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;example2&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>content</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;this be an example2.&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2021-09-02T00:00:00+09:00&#34;</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><p>Now we have two versions of the data with different text normalization rules. We can use the metadata to understand the data. And we should be able to run model training with different versions of the data.</p><h4 id=gold-layer-1>Gold Layer</h4><p>Now we need to have the data ready for our final task: document categorization. We need to have the data in a format that is ready to use for the training and inference.<br>Now we have the basic text input, but we don&rsquo;t have the targets for supervised learning. Let&rsquo;s say we use an external paid API to get the targets. The output of the API is a JSON file that contains the targets.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Json data-lang=Json><span class=line><span class=cl><span class=err>#</span> <span class=err>s</span><span class=mi>3</span><span class=err>:</span><span class=c1>//&lt;bucket_name&gt;/html-classification/annotated/2021-09-04/html-documents.json
</span></span></span><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://www.example.com&#34;</span><span class=p>,</span> <span class=nt>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;example - this be an example.&#34;</span><span class=p>,</span> <span class=nt>&#34;category&#34;</span><span class=p>:</span> <span class=s2>&#34;entertainment&#34;</span><span class=p>,</span> <span class=nt>&#34;timestamp&#34;</span><span class=p>:</span> <span class=s2>&#34;2021-09-01T00:00:00+09:00&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://www.example2.com&#34;</span><span class=p>,</span> <span class=nt>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;example2 - this be an example2.&#34;</span><span class=p>,</span> <span class=nt>&#34;category&#34;</span><span class=p>:</span> <span class=s2>&#34;politics&#34;</span><span class=p>,</span> <span class=nt>&#34;timestamp&#34;</span><span class=p>:</span> <span class=s2>&#34;2021-09-02T00:00:00+09:00&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=err>...</span>
</span></span></code></pre></td></tr></table></div></div><p>Metadata:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl>-<span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Description</span><span class=p>:</span><span class=w> </span><span class=l>HTML documents with title and content extracted, and text normalization applied, and targets added.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Data source</span><span class=p>:</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>s3://&lt;bucket_name&gt;/html-classification/preprocess/text-normalization/v2/2021-09-03/html-documents.json</span><span class=w> </span><span class=c># This allows us to trace the previous steps</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>https://www.example.com/api/v1/document-categorization </span><span class=w> </span><span class=c># the api </span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Date of data creation</span><span class=p>:</span><span class=w> </span><span class=ld>2021-09-04</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>workflow-name</span><span class=p>:</span><span class=w> </span><span class=l>annotation</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>SHA1</span><span class=p>:</span><span class=w> </span><span class=l>8b8ae027744d2f920eb1aeee676d589957de40cc</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Schema</span><span class=p>:</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>title</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>content</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>category</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Statistics</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>Number of rows</span><span class=p>:</span><span class=w> </span><span class=m>998</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>Number of columns</span><span class=p>:</span><span class=w> </span><span class=m>5</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Sample</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://www.example.com&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>title</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;example&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>content</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;this be an example.&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>category</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;entertainment&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2021-09-01T00:00:00+09:00&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://www.example2.com&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>title</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;example2&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>content</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;this be an example2.&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>category</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;politics&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2021-09-02T00:00:00+09:00&#34;</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><p>We use the v2 version of the data, and we add the targets to the data. Now we have the data ready for the training and inference.<br>When we train the model, we can push the metadata to MLFlow, as artifact or as parameter. This allows us to trace the data and the model.</p><h4 id=post-train-layer>Post Train Layer</h4><p>This is the step after the model training. We refine the data in this step with CleanLab. We try to rectify the mislabeled data and remove some outliers that are not related to the business.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Json data-lang=Json><span class=line><span class=cl><span class=err>#</span> <span class=err>s</span><span class=mi>3</span><span class=err>:</span><span class=c1>//&lt;bucket_name&gt;/html-classification/post-train/2021-09-05/html-documents.json
</span></span></span><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://www.example.com&#34;</span><span class=p>,</span> <span class=nt>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;example - this be an example.&#34;</span><span class=p>,</span> <span class=nt>&#34;category&#34;</span><span class=p>:</span> <span class=s2>&#34;entertainment&#34;</span><span class=p>,</span> <span class=nt>&#34;timestamp&#34;</span><span class=p>:</span> <span class=s2>&#34;2021-09-01T00:00:00+09:00&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://www.example2.com&#34;</span><span class=p>,</span> <span class=nt>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;example2 - this be an example2.&#34;</span><span class=p>,</span> <span class=nt>&#34;category&#34;</span><span class=p>:</span> <span class=s2>&#34;politics&#34;</span><span class=p>,</span> <span class=nt>&#34;timestamp&#34;</span><span class=p>:</span> <span class=s2>&#34;2021-09-02T00:00:00+09:00&#34;</span><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>Metadata:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl>-<span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Description</span><span class=p>:</span><span class=w> </span><span class=l>HTML documents with title and content extracted, and text normalization applied, and targets added, and mislabeled data removed.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Data source</span><span class=p>:</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>s3://&lt;bucket_name&gt;/html-classification/preprocess/annotated/2021-09-04/html-documents.json</span><span class=w> </span><span class=c># This allows us to trace the previous steps</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Date of data creation</span><span class=p>:</span><span class=w> </span><span class=ld>2021-09-05</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>workflow-name</span><span class=p>:</span><span class=w> </span><span class=l>clean-lab</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>SHA1</span><span class=p>:</span><span class=w> </span><span class=l>8b8ae027744d2f920eb1aeee676d589957de40cc</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Schema</span><span class=p>:</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>title</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>content</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>category</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=l>string</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Statistics</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>Number of rows</span><span class=p>:</span><span class=w> </span><span class=m>900</span><span class=w> </span><span class=c># reduced a lot of bad data </span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>Number of columns</span><span class=p>:</span><span class=w> </span><span class=m>5</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>Sample</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://www.example.com&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>title</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;example&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>content</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;this be an example.&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>category</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;entertainment&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2021-09-01T00:00:00+09:00&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>url</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://www.example2.com&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>title</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;example2&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>content</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;this be an example2.&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>category</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;politics&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>timestamp</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2021-09-02T00:00:00+09:00&#34;</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><h2 id=conclusion>Conclusion</h2><p>This is a very simple data management example. But it shows the basic idea of how to manage data in MLOps.<br>It&rsquo;s good to start with something simple and easy to understand. And then we can improve the data management incrementally.<br>We can begin with some nave formats like JSONL, and then we can use more advanced formats like Parquet, Delta Table, etc. We can use some simple tools like plain S3FS or git-lfs, and then we can use more advanced tools like Neptune, Pachyderm, lakeFS, etc. We can use some simple workflow tools like Argo Workflow, and then we can use more advanced tools like Airflow, Dagster, etc.<br>We can also use MLFlow to track the data we used for the training.</p><p>For me, the most important thing is to be able to track the data the clean way to allow us to acheive the goals we mentioned in the beginning of this article. This example showed we can do it with some simple tools. Minio can help us control the access, the metadata can help us understand the data, and the workflow tools can help us to manage the pipeline. And all this with a restrained budget.</p></section><footer class=article-footer><section class=article-tags><a href=/tags/mlops/>MLOps</a>
<a href=/tags/data-management/>Data Management</a>
<a href=/tags/nlp/>NLP</a>
<a href=/tags/dvc/>DVC</a>
<a href=/tags/s3/>S3</a>
<a href=/tags/minio/>Minio</a>
<a href=/tags/mlflow/>MLFlow</a></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/p/ml-huggingface-pipeline-as-a-service/><div class=article-details><h2 class=article-title>[ML] Huggingface Pipeline as a Service</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//hugo-theme-stack.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2023 -
2025 Haoxian's Blog</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.33.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.c922af694cc257bf1ecc41c0dd7b0430f9114ec280ccf67cd2c6ad55f5316c4e.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>